{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016033e8-14a1-4179-9d86-4adf70abcd76",
   "metadata": {},
   "source": [
    "# SSD Lite model on the cows dataset from ICAERUS/France\n",
    "Most of this is adapted from basic cookiecutter model training in pytorch.\n",
    "\n",
    "Dataset consists of three areas: Jalogny, Derval and Mauron: these directly correspond to train/test/val sets.\n",
    "I removed all images without an annotation in them (e.g. just a picture of a field, without a cow)\n",
    "* train: jalogny: x img, x annotations\n",
    "* test: derval: x imgs, x annotations\n",
    "* val: mauron: x imgs, x annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144c3ad-e2ae-4bf7-b62a-295fe1085358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Using cached grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard)\n",
      "  Using cached google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard)\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.24.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, pyasn1, markdown, grpcio, cachetools, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-2.0.0 cachetools-5.3.2 google-auth-2.25.2 google-auth-oauthlib-1.2.0 grpcio-1.60.0 markdown-3.5.1 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 werkzeug-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41757da-e949-4675-9aeb-fb2607e86833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.datasets import VOCDetection\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import ops\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import datapoints\n",
    "from torchvision.ops import generalized_box_iou_loss\n",
    "from torch.utils import tensorboard\n",
    "from torchvision.datasets import VisionDataset\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c699cb-b70c-4c48-b612-a6d2d6039ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(VisionDataset):\n",
    "    def __init__(self, images, labels, boxes, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.boxes = boxes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        boxes = torch.tensor(self.boxes[idx], dtype = torch.float32)\n",
    "        target = {'boxes': boxes,\n",
    "                 'labels': labels}\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6d09fb-7915-4c46-884f-11e6cbdffee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in the image_slicing.ipynb, the images are loaded and then tiled (in  a 320x320 grid), placed into a CustomDataset\n",
    "# with normalized values and all as tensors (), these are then pickled and stored.\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Create a VOC dataset\n",
    "train_dataset = torch.load(\"data/train_set.pkl\")\n",
    "val_dataset = torch.load(\"data/val_set.pkl\")\n",
    "# Create a DataLoader for the VOC dataset\n",
    "batch_size = 8\n",
    "shuffle = True\n",
    "\n",
    "#and put them in the loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, collate_fn = collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbbb5a-bf1d-4fb8-99c4-17ba3bac7f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "warmup_epochs = 50\n",
    "evaluate_every = 10\n",
    "\n",
    "# Create your SSD Lite model\n",
    "model = ssdlite320_mobilenet_v3_large(weights= \"SSDLite320_MobileNet_V3_Large_Weights.DEFAULT\")\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = generalized_box_iou_loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
    "# Set up the cosine annealing learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs - warmup_epochs)\n",
    "\n",
    "writer = tensorboard.SummaryWriter()\n",
    "\n",
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, targets = data        \n",
    "        \n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        #targets = [{k: v.to(device).long() if k == \"labels\" else v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = loss_dict[\"classification\"] + loss_dict[\"bbox_regression\"]\n",
    "\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Batch Loss: {losses}\")\n",
    "        \n",
    "            # Update the learning rate\n",
    "    scheduler.step()\n",
    "        # Log the training loss to Tensorboard\n",
    "    writer.add_scalar('Loss/train', losses.item(), epoch)\n",
    "   \n",
    "    \n",
    "      # Evaluate on the validation set every 'evaluate_every' epochs\n",
    "    if epoch % evaluate_every == 0:\n",
    "        with torch.no_grad():\n",
    "            val_losses = 0.0\n",
    "            for images, targets in val_loader:\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "                val_loss_dict = model(images, targets)\n",
    "                \n",
    "                val_losses += val_loss_dict[\"classification\"] + loss_dict[\"bbox_regression\"]\n",
    "\n",
    "            avg_val_loss = val_losses / len(val_loader)\n",
    "\n",
    "            # Log the validation loss to Tensorboard\n",
    "            writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "            print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss.item()}\")\n",
    "            torch.save(model.state_dict(), f\"models/ssdlite_cows_model_v4_e{epoch}.pth\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), f'models/ssdlite_cows_model_v4_{num_epochs}e.pth')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7891b921-d3aa-4464-aef8-bb9a25fac760",
   "metadata": {},
   "source": [
    "Epoch 1, Batch Loss: 2.1624016761779785\n",
    "Epoch 1, Validation Loss: 2.162400245666504\n",
    "Epoch 2, Batch Loss: 2.5404789447784424\n",
    "Epoch 3, Batch Loss: 2.3300535678863525\n",
    "Epoch 4, Batch Loss: 2.4105634689331055\n",
    "Epoch 5, Batch Loss: 2.106541156768799\n",
    "Epoch 6, Batch Loss: 2.1915464401245117\n",
    "Epoch 6, Validation Loss: 2.191544771194458\n",
    "Epoch 7, Batch Loss: 2.015090227127075\n",
    "Epoch 8, Batch Loss: 1.9103816747665405\n",
    "Epoch 9, Batch Loss: 2.6565113067626953\n",
    "Epoch 10, Batch Loss: 1.546593189239502\n",
    "Epoch 11, Batch Loss: 1.8698519468307495\n",
    "Epoch 11, Validation Loss: 1.8698517084121704\n",
    "Epoch 12, Batch Loss: 2.277885675430298\n",
    "Epoch 13, Batch Loss: 1.0736545324325562\n",
    "Epoch 14, Batch Loss: 1.4011064767837524\n",
    "Epoch 15, Batch Loss: 0.7211280465126038\n",
    "Epoch 16, Batch Loss: 1.552635669708252\n",
    "Epoch 16, Validation Loss: 1.5526351928710938\n",
    "Epoch 17, Batch Loss: 1.8985334634780884\n",
    "Epoch 18, Batch Loss: 1.0585334300994873\n",
    "Epoch 19, Batch Loss: 0.6549271941184998\n",
    "Epoch 20, Batch Loss: 0.6437249183654785\n",
    "Epoch 21, Batch Loss: 0.775252640247345\n",
    "Epoch 21, Validation Loss: 0.7752530574798584\n",
    "Epoch 22, Batch Loss: 0.5523011684417725\n",
    "Epoch 23, Batch Loss: 0.5858114957809448\n",
    "Epoch 24, Batch Loss: 0.8299723863601685\n",
    "Epoch 25, Batch Loss: 0.6758676171302795\n",
    "Epoch 26, Batch Loss: 0.37474769353866577\n",
    "Epoch 26, Validation Loss: 0.3747478425502777\n",
    "Epoch 27, Batch Loss: 0.4907954931259155\n",
    "Epoch 28, Batch Loss: 0.28217196464538574\n",
    "Epoch 29, Batch Loss: 0.4357515573501587\n",
    "Epoch 30, Batch Loss: 0.1401309370994568\n",
    "Epoch 31, Batch Loss: 0.1647355854511261\n",
    "Epoch 31, Validation Loss: 0.16473571956157684\n",
    "Epoch 32, Batch Loss: 0.15228570997714996\n",
    "Epoch 33, Batch Loss: 0.11974284052848816\n",
    "Epoch 34, Batch Loss: 0.16989053785800934\n",
    "Epoch 35, Batch Loss: 0.11060953140258789\n",
    "Epoch 36, Batch Loss: 0.23397697508335114\n",
    "Epoch 36, Validation Loss: 0.23397698998451233\n",
    "Epoch 37, Batch Loss: 0.10249509662389755\n",
    "Epoch 38, Batch Loss: 0.1783769279718399\n",
    "Epoch 39, Batch Loss: 0.27197781205177307\n",
    "Epoch 40, Batch Loss: 0.060597095638513565\n",
    "Epoch 41, Batch Loss: 0.2649507522583008\n",
    "Epoch 41, Validation Loss: 0.2649504840373993\n",
    "Epoch 42, Batch Loss: 0.08115487545728683\n",
    "Epoch 43, Batch Loss: 0.10914859920740128\n",
    "Epoch 44, Batch Loss: 0.08243907243013382\n",
    "Epoch 45, Batch Loss: 0.08893191814422607\n",
    "Epoch 46, Batch Loss: 0.05804527923464775\n",
    "Epoch 46, Validation Loss: 0.05804533138871193\n",
    "Epoch 47, Batch Loss: 0.3471693694591522\n",
    "Epoch 48, Batch Loss: 0.0683818981051445\n",
    "Epoch 49, Batch Loss: 0.08555656671524048\n",
    "Epoch 50, Batch Loss: 0.08576574176549911\n",
    "Epoch 51, Batch Loss: 0.10381092131137848\n",
    "Epoch 51, Validation Loss: 0.10381089895963669\n",
    "Epoch 52, Batch Loss: 0.047768350690603256\n",
    "Epoch 53, Batch Loss: 0.08078217506408691\n",
    "Epoch 54, Batch Loss: 0.04985416680574417\n",
    "Epoch 55, Batch Loss: 0.04265188053250313\n",
    "Epoch 56, Batch Loss: 0.0492166243493557\n",
    "Epoch 56, Validation Loss: 0.04921656474471092\n",
    "Epoch 57, Batch Loss: 0.044927652925252914\n",
    "Epoch 58, Batch Loss: 0.04169200733304024\n",
    "Epoch 59, Batch Loss: 0.09698423743247986\n",
    "Epoch 60, Batch Loss: 0.0698719173669815\n",
    "Epoch 61, Batch Loss: 0.08348662406206131\n",
    "Epoch 61, Validation Loss: 0.08348657935857773\n",
    "Epoch 62, Batch Loss: 0.06443209201097488\n",
    "Epoch 63, Batch Loss: 0.07328645884990692\n",
    "Epoch 64, Batch Loss: 0.025384951382875443\n",
    "Epoch 65, Batch Loss: 0.05251451954245567\n",
    "Epoch 66, Batch Loss: 0.031014230102300644\n",
    "Epoch 66, Validation Loss: 0.031014209613204002\n",
    "Epoch 67, Batch Loss: 0.02969858981668949\n",
    "Epoch 68, Batch Loss: 0.03139123320579529\n",
    "Epoch 69, Batch Loss: 0.040941447019577026\n",
    "Epoch 70, Batch Loss: 0.04247945919632912\n",
    "Epoch 71, Batch Loss: 0.05030020698904991\n",
    "Epoch 71, Validation Loss: 0.05030016601085663\n",
    "Epoch 72, Batch Loss: 0.04001690074801445\n",
    "Epoch 73, Batch Loss: 0.12307494133710861\n",
    "Epoch 74, Batch Loss: 0.06682360172271729\n",
    "Epoch 75, Batch Loss: 0.050678908824920654\n",
    "Epoch 76, Batch Loss: 0.02051289565861225\n",
    "Epoch 76, Validation Loss: 0.020512908697128296\n",
    "Epoch 77, Batch Loss: 0.024961793795228004\n",
    "Epoch 78, Batch Loss: 0.021898822858929634\n",
    "Epoch 79, Batch Loss: 0.07592733949422836\n",
    "Epoch 80, Batch Loss: 0.07748715579509735\n",
    "Epoch 81, Batch Loss: 0.09132784605026245\n",
    "Epoch 81, Validation Loss: 0.09132777899503708\n",
    "Epoch 82, Batch Loss: 0.03422539308667183\n",
    "Epoch 83, Batch Loss: 0.020913509652018547\n",
    "Epoch 84, Batch Loss: 0.05341031774878502\n",
    "Epoch 85, Batch Loss: 0.07039040327072144\n",
    "Epoch 86, Batch Loss: 0.2477205991744995\n",
    "Epoch 86, Validation Loss: 0.24772068858146667\n",
    "Epoch 87, Batch Loss: 0.05110390484333038\n",
    "Epoch 88, Batch Loss: 0.10275000333786011\n",
    "Epoch 89, Batch Loss: 0.03458305448293686\n",
    "Epoch 90, Batch Loss: 0.08632629364728928\n",
    "Epoch 91, Batch Loss: 0.029491905122995377\n",
    "Epoch 91, Validation Loss: 0.029491903260350227\n",
    "Epoch 92, Batch Loss: 0.017571212723851204\n",
    "Epoch 93, Batch Loss: 0.056979794055223465\n",
    "Epoch 94, Batch Loss: 0.048410408198833466\n",
    "Epoch 95, Batch Loss: 0.044813450425863266\n",
    "Epoch 96, Batch Loss: 0.03621485456824303\n",
    "Epoch 96, Validation Loss: 0.036214832216501236\n",
    "Epoch 97, Batch Loss: 0.030982185155153275\n",
    "Epoch 98, Batch Loss: 0.04555738717317581\n",
    "Epoch 99, Batch Loss: 0.02477923035621643\n",
    "Epoch 100, Batch Loss: 0.02978690154850483"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
